import {
  Classification,
  deDuplicateList,
  EntityPositions,
  FieldId,
  FileFieldData,
  getDataKeyFromFieldType,
  IError,
  Message,
  Paragraph,
  ParagraphClassification,
  Resource,
  UserClassification,
  UserFieldMetadata,
  TokenAnnotation,
  DEFAULT_NER_KEY,
  ConversationField,
  FIELD_TYPE,
  ConversationFieldPages,
} from '@nuclia/core';
import { SafeUrl } from '@angular/platform-browser';
import { forkJoin, map, Observable, of } from 'rxjs';

export type Thumbnail = { uri: string; blob: SafeUrl };
export type EditResourceView = 'preview' | 'resource' | 'classification' | 'annotation' | 'add-field';

export interface ParagraphWithText extends Paragraph {
  paragraphId: string;
  text: string;
}

export interface ParagraphWithTextAndClassifications extends ParagraphWithText {
  // labels added to the paragraph by the user, as well as cancellation of backend labels
  userClassifications: UserClassification[];
  // labels generated by the backend which weren't cancelled by the user
  generatedClassifications: Classification[];
}

export interface ParagraphWithTextAndAnnotations extends ParagraphWithText {
  annotations: EntityAnnotation[];
  annotatedText: string;
}

export interface ParagraphWithTextAndImage extends ParagraphWithText {
  imagePath?: string;
}

export interface EntityGroup {
  id: string;
  title: string;
  color: string;
  custom?: boolean;
  entities: string[];
}

export interface EntityAnnotation extends TokenAnnotation {
  family: string;
}

export const getParagraphs = (fieldId: FieldId, resource: Resource): Paragraph[] => {
  const dataKey = getDataKeyFromFieldType(fieldId.field_type);
  if (!dataKey || !resource.data[dataKey]) {
    return [];
  }
  return resource.data[dataKey]?.[fieldId.field_id]?.extracted?.metadata?.metadata?.paragraphs || [];
};

export const getConversationParagraphs = (fieldId: FieldId, resource: Resource, messages: Message[]): Paragraph[] => {
  const dataKey = getDataKeyFromFieldType(fieldId.field_type);
  if (!dataKey || !resource.data[dataKey]) {
    return [];
  }
  const metadata = resource.data[dataKey]?.[fieldId.field_id]?.extracted?.metadata;
  return Object.keys(metadata?.split_metadata || {})
    .filter((split) => messages.findIndex((item) => item.ident === split) >= 0)
    .sort((a, b) => messages.findIndex((item) => item.ident === a) - messages.findIndex((item) => item.ident === b))
    .reduce((acc, split) => [...acc, ...(metadata?.split_metadata?.[split]?.paragraphs || [])], [] as Paragraph[]);
};

export function getErrors(fieldId: FieldId, resource: Resource): IError | null {
  const dataKey = getDataKeyFromFieldType(fieldId.field_type);
  if (!dataKey || !resource.data[dataKey]) {
    return null;
  }
  return resource.data[dataKey]?.[fieldId.field_id]?.error || null;
}

export function getFieldMetadataForClassifications(
  field: FieldId,
  paragraphs: ParagraphWithTextAndClassifications[],
  existingEntries: UserFieldMetadata[],
): UserFieldMetadata[] {
  const paragraphClassifications: ParagraphClassification[] = paragraphs
    .map((p) =>
      p.userClassifications.length > 0
        ? {
            key: p.paragraphId,
            classifications: p.userClassifications,
          }
        : null,
    )
    .filter((classification) => !!classification) as ParagraphClassification[];

  let existingField = false;
  const newEntries = existingEntries.map((entry) => {
    if (entry.field.field === field.field_id && entry.field.field_type === field.field_type) {
      existingField = true;
      return {
        ...entry,
        paragraphs: paragraphClassifications,
      };
    } else {
      return entry;
    }
  });

  if (!existingField) {
    newEntries.push({
      field: { field: field.field_id, field_type: field.field_type },
      paragraphs: paragraphClassifications,
    });
  }
  return newEntries;
}

export function addEntitiesToGroups(allGroups: EntityGroup[], entitiesMap: { [key: string]: string[] }) {
  Object.entries(entitiesMap).forEach(([groupId, entities]) => {
    const group = allGroups.find((g) => g.id === groupId);
    if (group) {
      entities.forEach((entity) => {
        if (!group.entities.includes(entity)) {
          group.entities.push(entity);
        }
      });
    }
  });
}

export function getGeneratedFieldAnnotations(
  resource: Resource,
  fieldId: FieldId,
  families: EntityGroup[],
): EntityAnnotation[] {
  const dataKey = getDataKeyFromFieldType(fieldId.field_type);
  const annotations: EntityAnnotation[] = [];
  if (dataKey && resource.data[dataKey]) {
    const positions: EntityPositions =
      resource.data[dataKey]?.[fieldId.field_id]?.extracted?.metadata?.metadata.positions || {};
    Object.entries(positions).forEach(([family, entityPosition]) => {
      const familyId = family.split('/')[0];
      const familyTitle = families.find((group) => group.id === familyId)?.title || '';
      entityPosition.position.forEach((position) =>
        annotations.push({
          klass: familyId,
          family: familyTitle,
          token: entityPosition.entity,
          start: position.start,
          end: position.end,
        }),
      );
    });
    Object.entries(resource.data[dataKey]?.[fieldId.field_id]?.extracted?.metadata?.metadata.entities || {})
      .filter(([key]) => key !== DEFAULT_NER_KEY)
      .forEach(([, entities]) => {
        entities.entities.forEach((entity) => {
          entity.positions.forEach((position) => {
            annotations.push({
              klass: entity.label,
              family: entity.label,
              token: entity.text,
              start: position.start,
              end: position.end,
            });
          });
        });
      });
  }
  return annotations;
}

export function isSameAnnotation(a: EntityAnnotation, b: EntityAnnotation) {
  return a.end === b.end && a.start === b.start && a.family === b.family && a.klass === b.klass && a.token === b.token;
}

export function getParagraphAnnotations(
  allAnnotations: EntityAnnotation[],
  paragraph: Paragraph,
  families: EntityGroup[],
) {
  const annotations: EntityAnnotation[] = allAnnotations
    .filter(
      (annotation) =>
        families.find((family) => family.id === annotation.klass) &&
        annotation.start >= (paragraph.start || 0) &&
        annotation.end <= (paragraph.end || 0),
    )
    .map((annotation) => ({
      ...annotation,
      start: annotation.start - (paragraph.start || 0),
      end: annotation.end - (paragraph.start || 0),
    }))
    .sort(sortByPosition);
  return annotations;
}

export function sortByPosition(a: EntityAnnotation, b: EntityAnnotation): number {
  if (a.start < b.start) {
    return -1;
  } else if (a.start > b.start) {
    return 1;
  } else {
    return 0;
  }
}

export function getHighlightedAnnotations(allAnnotations: EntityAnnotation[]): EntityAnnotation[] {
  return allAnnotations.reduce((list, annotation) => {
    if (!list.find((item) => isSameAnnotation(annotation, item))) {
      list.push(annotation);
    }
    return list;
  }, [] as EntityAnnotation[]);
}

export function getAnnotatedText(
  paragraphId: string,
  paragraphText: string,
  annotations: EntityAnnotation[],
  selectedFamily?: EntityGroup | null,
): string {
  let textWithMarks = '';
  let currentIndex = 0;
  annotations.forEach((annotation) => {
    let highlightedStyle = '';
    if (selectedFamily?.id === annotation.klass) {
      highlightedStyle = `style="background-color:${selectedFamily.color}"`;
    }
    textWithMarks += `${sliceUnicode(paragraphText, currentIndex, annotation.start)}<mark title="${
      annotation.family
    }" family="${annotation.klass}" start="${annotation.start}" end="${annotation.end}" token="${
      annotation.token
    }" ${highlightedStyle} >${sliceUnicode(paragraphText, annotation.start, annotation.end)}</mark>`;
    currentIndex = annotation.end;
  });
  textWithMarks += sliceUnicode(paragraphText, currentIndex);
  return textWithMarks;
}

/**
 * In JavaScript, 'ðŸ¤–'.length is 2, but all positions in API responses are based on Python and in Python len('ðŸ¤–') is 1.
 * By converting the string to an array, we can get the correct length and slicing becomes consistent with the API
 * (because the array will split the string into characters, no matter how long they are)
 * @param str
 * @param start
 * @param end
 */
export const sliceUnicode = (str: string | string[] | undefined, start?: number, end?: number) => {
  if (!str) {
    return '';
  }
  if (!Array.isArray(str)) {
    str = Array.from(str);
  }
  return str.slice(start, end).join('');
};

export const getClassificationsPayload = (resource: Resource, labels: Classification[]): UserClassification[] => {
  const extracted = deDuplicateList(
    (resource.computedmetadata?.field_classifications || []).reduce((acc, field) => {
      return acc.concat(field.classifications || []);
    }, [] as Classification[]),
  );
  const userClassifications = labels.filter(
    (label) => !extracted.some((l) => l.labelset === label.labelset && l.label === label.label),
  );
  const cancellations = extracted
    .filter((label) => !labels.some((l) => l.labelset === label.labelset && l.label === label.label))
    .map((label) => ({ ...label, cancelled_by_user: true }));
  return [...userClassifications, ...cancellations];
};

export function getParagraphsWithImages(
  paragraphs: ParagraphWithText[],
  fieldData: FileFieldData,
): ParagraphWithTextAndImage[] {
  const extractedData = (fieldData as FileFieldData)?.extracted?.file;
  const imagePositions = Object.entries(extractedData?.nested_list_position || {}).filter(
    ([filename]) => extractedData?.file_generated?.[filename]?.content_type?.startsWith('image/'),
  );
  if (imagePositions.length === 0) {
    return paragraphs;
  }
  return paragraphs.reduce((acc, paragraph, index, all) => {
    imagePositions.forEach(([filename, positions]) => {
      positions.positions.forEach((position) => {
        if ((position.start || 0) > (all[index - 1]?.end || 0) && (position.start || 0) <= (paragraph.end || 0)) {
          acc.push({
            text: '',
            paragraphId: `${filename}-${position.start}-${position.end}`,
            imagePath: extractedData?.file_generated?.[filename]?.uri || '',
          });
        }
      });
    });
    acc.push(paragraph);
    return acc;
  }, [] as ParagraphWithTextAndImage[]);
}

export function getCustomEntities(resource: Resource): { [key: string]: string[] } {
  return resource
    .getFields()
    .map((field) => {
      return Object.entries(field.extracted?.metadata?.metadata?.entities || {})
        .filter(([key]) => key !== DEFAULT_NER_KEY)
        .reduce(
          (acc, [, entities]) => {
            entities.entities.forEach((entity) => {
              acc[entity.label] = (acc[entity.label] || []).concat([entity.text]);
            });
            return acc;
          },
          {} as { [key: string]: string[] },
        );
    })
    .reduce(
      (acc, val) => {
        Object.entries(val).forEach(([key, value]) => {
          acc[key] = (acc[key] || []).concat(value);
        });
        return acc;
      },
      {} as { [key: string]: string[] },
    );
}

export function getTotalMessagePages(fieldId: FieldId, resource: Resource): number {
  return (resource.data['conversations']?.[fieldId.field_id]?.value as ConversationFieldPages)?.pages || 0;
}

export function getMessages(fieldId: FieldId, resource: Resource, pageStart: number, pageEnd?: number): Observable<Message[] | null> {
  let pages = [pageStart]
  if (pageEnd !== undefined && pageEnd > pageStart) {
    for (let i = pageStart + 1; i<=pageEnd; i++) {
      pages.push(i);
    }
  }
  return fieldId.field_type === FIELD_TYPE.conversation
    ? forkJoin(
        pages.map((page) =>
          resource
            .getField(fieldId.field_type, fieldId.field_id, undefined, undefined, page)
            .pipe(map((field) => (field.value as ConversationField).messages)),
        ),
      ).pipe(map((data) => data.reduce((acc, curr) => acc.concat(curr), [] as Message[])))
    : of(null);
}
